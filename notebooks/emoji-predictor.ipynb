{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Emoji Predictor - DL project, Dec. 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:26:15.791598Z",
     "start_time": "2020-12-16T23:26:15.784737Z"
    }
   },
   "outputs": [],
   "source": [
    "import emojis\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import CamembertModel, CamembertTokenizer, CamembertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to to the Twitter API, we downloaded:\n",
    "* ~4.5M raw tweets\n",
    "* in French\n",
    "* posted between September and December 2019\n",
    "* containing emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:51:04.362830Z",
     "start_time": "2020-12-16T19:50:59.283919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 4529208 tweets. See examples below:\n",
      "\n",
      "@chlechevalier @agnesbuzyn @googlenews macron n a pas honte de faire la fÃªte ğŸ¥³ , brizitte se dandine habillÃ©e par un grand couturier , et pendant ce temps - lÃ  , le peuple se meurt ğŸ˜¡ ğŸ˜¡ ğŸ˜¡ ğŸ˜¡\n",
      "\n",
      "@yoongichana la petite Ã©tait blonde 5 ans jcp pk elle est morte mais j â€™ habite au 3e Ã©tage et j â€™ entendais qlq â€™ 1 toquÃ© Ã  la fenÃªtre de ma chambre alors moi j â€™ ouvre comme une conne et la son esprit Ã©tait dans 1 ballon ğŸˆ le ballon explose tt est devenu noir en 1sec j â€™ ai hurlÃ© ma mÃ¨re / sÅ“ur aussi\n",
      "\n",
      "et vous ? ğŸ¥° bonne annÃ©e les amis ! ğŸ’ƒ twitterlink\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/Thomas/Downloads/emoji-predictor/tweets_fr.txt') as tweets:\n",
    "    line1 = tweets.readline()\n",
    "    line2 = tweets.readline()\n",
    "    line3 = tweets.readline()\n",
    "    counter = 3\n",
    "    for x in tweets:\n",
    "        counter += 1\n",
    "    print(f'We have {counter} tweets. See examples below:\\n')\n",
    "    print(line1)\n",
    "    print(line2)\n",
    "    print(line3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went through several preprocessing steps to clean the tweets, before we were able to feed them to CamemBERT for embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Exclude spam / bots**\n",
    "\n",
    "The first preprocessing step was to **exclude spamming and bots**, which often use multiple emojis without real meaning / relationship to the actual text. For that, we **deleted the tweets containing more than 5 emojis**, and we kept **only 1 tweet per single user id** (which avoids bots posting multiple spam tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Extract emojis to label tweets**\n",
    "\n",
    "We **extracted the emojis** with regular expressions and the `emojis` package, in order to use them to label each tweet. A tweet will therefore be able to have **multiple labels**. We encode labels in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Clean text**\n",
    "\n",
    "Finally, to clean the raw text, we **removed tags (@ and # words)** and the 'twitterlink' word (corresponding to hyperlinks in the tweets), so that we have ready-to-tokenize text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and test the cleaning fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:42:42.130599Z",
     "start_time": "2020-12-16T23:42:42.114633Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \n",
    "    # lower text and remove accents\n",
    "    text = unidecode(text.lower())\n",
    "\n",
    "    # remove numbers, words starting with # or @, and 'twitterlink' words    \n",
    "    text = re.sub(r'#\\S+|@\\S+|\\d+|twitterlink', r'', text)\n",
    "    \n",
    "    # remove remaining punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # return text with single whitespaces\n",
    "    return ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:10.887261Z",
     "start_time": "2020-12-16T19:54:10.864085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('je me tape raleurs qui n arretent pas depuis mn', ['ğŸ˜“']),\n",
       " ('sera une annee encore plus fruisissante le voyage commence',\n",
       "  ['ğŸ˜œ', 'ğŸ›¬', 'ğŸ˜‰']),\n",
       " ('j vais encore arreter encore fois et je reprendrais plus', ['ğŸ‘'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on 3 tweets\n",
    "\n",
    "test = [\"@vita_despi je me tape 3 rÃ¢leurs qui n '  arrÃªtent pas depuis 10mn !! #waiting ğŸ˜“ğŸ˜“\",\n",
    "        \" 2020 sera une annÃ©e encore plus fruisissante ğŸ˜‰ le voyage commence ! ğŸ›¬ #quiabuboira ğŸ˜œ\",\n",
    "        \"j â€™ vais encore arrÃªter , encore 1 fois et je reprendrais plus ğŸ‘ twitterlink \"]\n",
    "\n",
    "output = []\n",
    "for x in test:\n",
    "    line = (clean(x), list(emojis.get(x)))\n",
    "    output.append(line)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the 100 most common emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:21.215198Z",
     "start_time": "2020-12-16T19:54:16.073244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000"
     ]
    }
   ],
   "source": [
    "# clean a part of the dataset (10k), from which we will extract the most common emojis\n",
    "\n",
    "with open('/Users/Thomas/Downloads/emoji-predictor/tweets_fr.txt') as tweets:\n",
    "    with open('/Users/Thomas/Downloads/emoji-predictor/10k_tweets_labelled.txt', 'w') as output:\n",
    "        N_TWEETS = 10000\n",
    "        delim = \"\"\n",
    "        counter = 0\n",
    "        for tweet in tweets:\n",
    "            if counter >= N_TWEETS: break\n",
    "            line = (clean(tweet), list(emojis.get(tweet)))\n",
    "            output.write(delim+str(line))\n",
    "            delim = \",\\n\"\n",
    "            counter += 1\n",
    "            print(f'\\r{counter}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:21.487656Z",
     "start_time": "2020-12-16T19:54:21.220192Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ğŸ˜‚',\n",
       " 'ğŸ˜­',\n",
       " 'ğŸ‘‰',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ™',\n",
       " 'ğŸ˜‰',\n",
       " 'ğŸ”¥',\n",
       " 'ğŸ¤£',\n",
       " 'ğŸ˜…',\n",
       " 'ğŸ‘',\n",
       " 'ğŸ‰',\n",
       " 'ğŸ’ª',\n",
       " 'ğŸ¤”',\n",
       " 'ğŸ˜Š',\n",
       " 'ğŸ‘Œ',\n",
       " 'âœ¨',\n",
       " 'ğŸ¥°',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜”',\n",
       " 'ğŸ‘',\n",
       " 'ğŸ˜˜',\n",
       " 'ğŸ˜±',\n",
       " 'ğŸ¥º',\n",
       " 'âœ…',\n",
       " 'ğŸ™„',\n",
       " 'ğŸ‘€',\n",
       " 'ğŸ’•',\n",
       " 'ğŸ¶',\n",
       " 'ğŸ˜€',\n",
       " 'ğŸ˜Œ',\n",
       " 'ğŸ¤©',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜¡',\n",
       " 'ğŸ’€',\n",
       " 'ğŸ¤ª',\n",
       " 'ğŸ‘‡',\n",
       " 'ğŸ˜¤',\n",
       " 'ğŸ¥³',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ˜´',\n",
       " 'ğŸ’™',\n",
       " 'ğŸ˜¢',\n",
       " 'ğŸ˜¥',\n",
       " 'ğŸ”´',\n",
       " 'ğŸ˜³',\n",
       " 'ğŸ¥µ',\n",
       " 'ğŸ¤“',\n",
       " 'ğŸ¤¯',\n",
       " 'ğŸ„',\n",
       " 'ğŸ˜œ',\n",
       " 'ğŸ¬',\n",
       " 'ğŸ“¸',\n",
       " 'ğŸ™‚',\n",
       " 'ğŸ¤«',\n",
       " 'ğŸ˜ª',\n",
       " 'ğŸ™ˆ',\n",
       " 'ğŸ‘‹',\n",
       " 'ğŸ˜‹',\n",
       " 'ğŸ˜“',\n",
       " 'ğŸ¤',\n",
       " 'âœŠ',\n",
       " 'ğŸ’”',\n",
       " 'ğŸ“º',\n",
       " 'ğŸ™ƒ',\n",
       " 'ğŸ¤',\n",
       " 'ğŸ¤¦',\n",
       " 'ğŸ¤·',\n",
       " 'ğŸ§',\n",
       " 'â³',\n",
       " 'ğŸ‘¨',\n",
       " 'ğŸ€',\n",
       " 'ğŸ',\n",
       " 'ğŸ˜‡',\n",
       " 'ğŸ¤—',\n",
       " 'ğŸ¤®',\n",
       " 'ğŸ‚',\n",
       " 'ğŸ’›',\n",
       " 'ğŸ’œ',\n",
       " 'ğŸ’¡',\n",
       " 'ğŸ˜',\n",
       " 'ğŸ™‹',\n",
       " 'ğŸš€',\n",
       " 'ğŸ¤’',\n",
       " 'ğŸ‘©',\n",
       " 'ğŸ˜ƒ',\n",
       " 'ğŸ˜ ',\n",
       " 'ğŸ˜¶',\n",
       " 'ğŸ¤§',\n",
       " 'ğŸ¤­',\n",
       " 'ğŸ¥',\n",
       " 'ğŸ–¤',\n",
       " 'ğŸ˜»',\n",
       " 'ğŸš¨',\n",
       " 'âš½',\n",
       " 'ğŸ“š',\n",
       " 'ğŸ˜’',\n",
       " 'ğŸ†',\n",
       " 'ğŸ˜–',\n",
       " 'ğŸ˜¬',\n",
       " 'ğŸ˜°']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 100 most common emojis\n",
    "\n",
    "with open('/Users/Thomas/Downloads/emoji-predictor/10k_tweets_labelled.txt') as tweets:\n",
    "    emoji_list = []\n",
    "    for tweet in tweets:\n",
    "        x = ast.literal_eval(tweet)\n",
    "        emoji_list.extend(x[0][1])\n",
    "    emoji_list = np.array(emoji_list)\n",
    "\n",
    "unique, counts = np.unique(emoji_list, return_counts=True)\n",
    "emoji_list = list(sorted(dict(zip(unique, counts)).items(), key=lambda item: item[1], reverse = True))\n",
    "emoji_list = [x[0] for x in emoji_list]\n",
    "emoji_list = emoji_list[:100]\n",
    "\n",
    "with open('/Users/Thomas/Downloads/emoji-predictor/top100.txt', 'w') as output:\n",
    "    output.write(str(emoji_list))\n",
    "    \n",
    "emoji_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding and tweet embedding using CamemBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CamemBERT and check it works fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With pure torch / fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:26:20.689064Z",
     "start_time": "2020-12-16T22:26:07.277696Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/Thomas/.cache/torch/hub/pytorch_fairseq_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerSentenceEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(32005, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load camembert\n",
    "camembert = torch.hub.load('pytorch/fairseq', 'camembert')\n",
    "camembert.eval() # disable dropout (or leave in train mode to finetune)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:26:20.924857Z",
     "start_time": "2020-12-16T22:26:20.693746Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Le deep learning est une sacrÃ©e rÃ©volution',\n",
       "  0.2869814932346344,\n",
       "  ' rÃ©volution'),\n",
       " ('Le deep learning est une sacrÃ©e invention',\n",
       "  0.1455322653055191,\n",
       "  ' invention'),\n",
       " ('Le deep learning est une sacrÃ©e innovation',\n",
       "  0.04289475828409195,\n",
       "  ' innovation')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that it works\n",
    "masked_line = \"Le deep learning est une sacrÃ©e <mask>\"\n",
    "camembert.fill_mask(masked_line, topk=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:32:47.394708Z",
     "start_time": "2020-12-16T22:32:47.240846Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et vous bonne annee les amis\n",
      "tensor([    5,    14,    39,   317, 25315,    19,   784,     6])\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# try embedding a short sentence\n",
    "\n",
    "text = \"et vous bonne annee les amis\"\n",
    "print(text)\n",
    "\n",
    "# tokenize sentence\n",
    "tokens = camembert.encode(text)\n",
    "print(tokens)\n",
    "\n",
    "# run camembert and keep only the last layer\n",
    "last_layer_features = camembert.extract_features(tokens, return_all_hiddens=False)\n",
    "print(last_layer_features.size())\n",
    "\n",
    "# METHOD 1 - POOLING\n",
    "# squeeze empty dimension (dim 0) and average over all tokens (dim 1) to get sentence embedding\n",
    "sentence_embedding = torch.squeeze(last_layer_features)\n",
    "sentence_embedding = torch.mean(sentence_embedding, dim=0)\n",
    "print(sentence_embedding.size())\n",
    "\n",
    "# METHOD 2 - CLS TOKEN\n",
    "# squeeze empty dimension (dim 0) and keep only the CLS token, in first position\n",
    "sentence_embedding = torch.squeeze(last_layer_features)\n",
    "sentence_embedding = sentence_embedding[0,:]\n",
    "print(sentence_embedding.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With HuggingFace transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:27:13.830314Z",
     "start_time": "2020-12-16T22:27:08.221089Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model = CamembertModel.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:27:16.143603Z",
     "start_time": "2020-12-16T22:27:15.936265Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 14, 39, 317, 25315, 19, 784, 6]\n",
      "['<s>', 'â–et', 'â–vous', 'â–bonne', 'â–annee', 'â–les', 'â–amis', '</s>']\n",
      "torch.Size([1, 8, 768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "text = \"et vous bonne annee les amis\"\n",
    "\n",
    "# tokenize sentence\n",
    "token_ids = tokenizer.encode(text)\n",
    "tokens = [tokenizer._convert_id_to_token(idx) for idx in token_ids]\n",
    "print(token_ids)\n",
    "print(tokens) # <s> is the classification token\n",
    "\n",
    "# run model\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "# forward method returns a tuple (we only want the logits, first element)\n",
    "output = model(token_ids)[0]\n",
    "print(output.size())\n",
    "\n",
    "# only grab output of CLS token (<s>), which is the first token\n",
    "cls_out = output.squeeze()[0]\n",
    "print(cls_out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to our dataset to create tweet embeddings and label encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we embed the **first 200 tweets** that contain at least one of the top 100 emojis, and we assign them a one-hot encoded label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:48:34.995099Z",
     "start_time": "2020-12-16T22:48:02.742244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200"
     ]
    }
   ],
   "source": [
    "# create a csv dataset with encoded labels\n",
    "\n",
    "with open('/Users/Thomas/Downloads/emoji-predictor/top100.txt') as f:\n",
    "    emoji_list = ast.literal_eval(f.read())\n",
    "    \n",
    "with open('/Users/Thomas/Downloads/emoji-predictor/10k_tweets_labelled.txt') as tweets:    \n",
    "    \n",
    "    clean_tweets = []\n",
    "    embedded_tweets = []\n",
    "    labels = []\n",
    "    counter = 0\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        if counter >= 200: break\n",
    "        x = ast.literal_eval(tweet)\n",
    "        label = np.array([emoji in x[0][1] for emoji in emoji_list], dtype=int)\n",
    "        if sum(label) > 0:\n",
    "            \n",
    "            # save clean tweet\n",
    "            clean_tweets.append(x[0][0])\n",
    "            \n",
    "            # save label\n",
    "            labels.append(label)\n",
    "            \n",
    "            # embed tweet\n",
    "            tokens = camembert.encode(x[0][0])\n",
    "            last_layer_features = camembert.extract_features(tokens, return_all_hiddens=False)\n",
    "            sentence_embedding = torch.squeeze(last_layer_features)\n",
    "            #sentence_embedding = torch.mean(sentence_embedding, dim=0) # METHOD 1 - POOLING\n",
    "            sentence_embedding = sentence_embedding[0,:] # METHOD 2 - CLS TOKEN\n",
    "            embedded_tweets.append(sentence_embedding.detach().numpy())\n",
    "            \n",
    "            # display counter\n",
    "            counter += 1\n",
    "            print(f'\\r{counter}', end='')\n",
    "    \n",
    "    labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T22:48:38.332527Z",
     "start_time": "2020-12-16T22:48:35.002696Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>emoji_0</th>\n",
       "      <th>emoji_1</th>\n",
       "      <th>emoji_2</th>\n",
       "      <th>emoji_3</th>\n",
       "      <th>emoji_4</th>\n",
       "      <th>emoji_5</th>\n",
       "      <th>emoji_6</th>\n",
       "      <th>emoji_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emoji_90</th>\n",
       "      <th>emoji_91</th>\n",
       "      <th>emoji_92</th>\n",
       "      <th>emoji_93</th>\n",
       "      <th>emoji_94</th>\n",
       "      <th>emoji_95</th>\n",
       "      <th>emoji_96</th>\n",
       "      <th>emoji_97</th>\n",
       "      <th>emoji_98</th>\n",
       "      <th>emoji_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>macron n a pas honte de faire la fete brizitte...</td>\n",
       "      <td>[-0.08949693, 0.16357468, 0.042515405, 0.05421...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et vous bonne annee les amis</td>\n",
       "      <td>[-0.034138117, 0.09090688, 0.13786273, -0.0594...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>villa brulee bientot la venue de mujdat</td>\n",
       "      <td>[-0.06162864, 0.20532067, 0.06378474, -0.03820...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mary poppins supercalifragilisticexpialidociou...</td>\n",
       "      <td>[-0.071972005, 0.31007147, 0.063247345, -0.070...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>le seul truc qui me choque dans house of cards...</td>\n",
       "      <td>[-0.009053078, 0.106543705, 0.004008528, 0.074...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>oh petard je vais me mettre a l impression je ...</td>\n",
       "      <td>[-0.08813255, 0.11456461, 0.08066056, -0.04078...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>j ai un pass de g qui a fait h</td>\n",
       "      <td>[-0.018228939, 0.15765423, 0.0024061128, -0.05...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>t as raison</td>\n",
       "      <td>[-0.16982707, 0.21184546, 0.19472101, -0.15934...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tres tres bonne question j attend les reponses</td>\n",
       "      <td>[-0.08709042, 0.28426468, -0.0034655817, -0.07...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>le marche de noel aura lieu demain a partir de...</td>\n",
       "      <td>[-0.06366463, 0.0940409, 0.10986172, -0.087324...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  \\\n",
       "0    macron n a pas honte de faire la fete brizitte...   \n",
       "1                         et vous bonne annee les amis   \n",
       "2              villa brulee bientot la venue de mujdat   \n",
       "3    mary poppins supercalifragilisticexpialidociou...   \n",
       "4    le seul truc qui me choque dans house of cards...   \n",
       "..                                                 ...   \n",
       "195  oh petard je vais me mettre a l impression je ...   \n",
       "196                     j ai un pass de g qui a fait h   \n",
       "197                                        t as raison   \n",
       "198     tres tres bonne question j attend les reponses   \n",
       "199  le marche de noel aura lieu demain a partir de...   \n",
       "\n",
       "                                            embeddings  emoji_0  emoji_1  \\\n",
       "0    [-0.08949693, 0.16357468, 0.042515405, 0.05421...        0        0   \n",
       "1    [-0.034138117, 0.09090688, 0.13786273, -0.0594...        0        0   \n",
       "2    [-0.06162864, 0.20532067, 0.06378474, -0.03820...        0        0   \n",
       "3    [-0.071972005, 0.31007147, 0.063247345, -0.070...        0        0   \n",
       "4    [-0.009053078, 0.106543705, 0.004008528, 0.074...        0        0   \n",
       "..                                                 ...      ...      ...   \n",
       "195  [-0.08813255, 0.11456461, 0.08066056, -0.04078...        1        0   \n",
       "196  [-0.018228939, 0.15765423, 0.0024061128, -0.05...        0        0   \n",
       "197  [-0.16982707, 0.21184546, 0.19472101, -0.15934...        1        0   \n",
       "198  [-0.08709042, 0.28426468, -0.0034655817, -0.07...        0        0   \n",
       "199  [-0.06366463, 0.0940409, 0.10986172, -0.087324...        0        0   \n",
       "\n",
       "     emoji_2  emoji_3  emoji_4  emoji_5  emoji_6  emoji_7  ...  emoji_90  \\\n",
       "0          0        0        0        0        0        0  ...         0   \n",
       "1          0        0        0        0        0        0  ...         0   \n",
       "2          0        0        0        0        0        0  ...         0   \n",
       "3          0        1        0        0        0        0  ...         0   \n",
       "4          0        0        0        0        0        0  ...         0   \n",
       "..       ...      ...      ...      ...      ...      ...  ...       ...   \n",
       "195        0        0        0        0        0        0  ...         0   \n",
       "196        0        0        0        0        0        0  ...         0   \n",
       "197        0        0        0        0        0        0  ...         0   \n",
       "198        0        0        0        0        0        0  ...         0   \n",
       "199        0        0        0        0        0        0  ...         0   \n",
       "\n",
       "     emoji_91  emoji_92  emoji_93  emoji_94  emoji_95  emoji_96  emoji_97  \\\n",
       "0           0         0         0         0         0         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         0         0   \n",
       "4           0         0         0         0         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195         0         0         0         0         0         0         0   \n",
       "196         0         0         0         0         0         0         0   \n",
       "197         0         0         0         0         0         0         0   \n",
       "198         0         0         0         0         0         0         0   \n",
       "199         0         0         0         0         0         0         0   \n",
       "\n",
       "     emoji_98  emoji_99  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "2           0         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "195         0         0  \n",
       "196         0         0  \n",
       "197         0         0  \n",
       "198         0         0  \n",
       "199         0         0  \n",
       "\n",
       "[200 rows x 102 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['tweets'] = clean_tweets\n",
    "df['embeddings'] = embedded_tweets\n",
    "for i in range(100):\n",
    "    df[f'emoji_{i}'] = labels[:,i]\n",
    "df.to_csv('/Users/Thomas/Downloads/emoji-predictor/encoded_data.csv')\n",
    "#df = df[:1000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:07:21.466896Z",
     "start_time": "2020-12-16T23:07:21.450986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 768)\n",
      "(180, 100)\n",
      "(20, 768)\n",
      "(20, 100)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "\n",
    "train_prop = 0.9\n",
    "test_idx = int(train_prop*len(df))\n",
    "x = np.concatenate(df['embeddings'].values)\n",
    "x = np.reshape(x, (200, 768))\n",
    "y = df.drop(['embeddings', 'tweets'], axis=1).values\n",
    "\n",
    "x_train = x[:test_idx]\n",
    "y_train = y[:test_idx]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "x_test = x[test_idx:]\n",
    "y_test = y[test_idx:]\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:07:28.318067Z",
     "start_time": "2020-12-16T23:07:28.170186Z"
    }
   },
   "outputs": [],
   "source": [
    "# build classification model\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(768, activation=\"relu\"),\n",
    "        layers.Dense(334, activation=\"relu\"),\n",
    "        layers.Dense(100, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics = tf.keras.metrics.BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:07:39.604121Z",
     "start_time": "2020-12-16T23:07:37.700777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "18/18 [==============================] - 1s 24ms/step - loss: 0.4319 - binary_crossentropy: 0.4319 - val_loss: 0.1075 - val_binary_crossentropy: 0.1075\n",
      "Epoch 2/4\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.1007 - binary_crossentropy: 0.1007 - val_loss: 0.0836 - val_binary_crossentropy: 0.0836\n",
      "Epoch 3/4\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0684 - binary_crossentropy: 0.0684 - val_loss: 0.0688 - val_binary_crossentropy: 0.0688\n",
      "Epoch 4/4\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0610 - binary_crossentropy: 0.0610 - val_loss: 0.0683 - val_binary_crossentropy: 0.0683\n",
      "dict_keys(['loss', 'binary_crossentropy', 'val_loss', 'val_binary_crossentropy'])\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(x_train, y_train, validation_split = 0.2, epochs = 4, batch_size = 8)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:07:39.960221Z",
     "start_time": "2020-12-16T23:07:39.608523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training curves\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:22:58.754638Z",
     "start_time": "2020-12-16T23:22:58.650691Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(\"/Users/Thomas/Downloads/emoji-predictor/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:09:30.090676Z",
     "start_time": "2020-12-16T23:09:30.032001Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:20:45.476105Z",
     "start_time": "2020-12-16T23:20:45.450068Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted (0.0611): ğŸ˜­   true: ['ğŸ¤®']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0676): ğŸ˜­   true: ['ğŸ˜ƒ']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0623): ğŸ˜­   true: ['ğŸ¤—']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0653): ğŸ˜­   true: ['ğŸ˜‰', 'ğŸ¤·']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0674): ğŸ˜‚   true: ['ğŸš¨']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0696): ğŸ˜­   true: ['ğŸ¥µ']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0634): ğŸ˜­   true: ['ğŸ’™']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0642): ğŸ˜­   true: ['ğŸ¤§']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0648): ğŸ˜­   true: ['ğŸ™']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0644): ğŸ˜­   true: ['ğŸ‘‡']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0676): ğŸ˜‚   true: ['âœ…', 'ğŸ˜ƒ']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0725): ğŸ˜­   true: ['ğŸ˜°']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0768): ğŸ˜‚   true: ['ğŸ¬']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0725): ğŸ˜­   true: ['ğŸ˜±']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0743): ğŸ˜­   true: ['ğŸ“¸']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0625): ğŸ˜­   true: ['ğŸ˜‚']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0757): ğŸ˜­   true: ['ğŸ¤’']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0740): ğŸ˜­   true: ['ğŸ˜‚']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0628): ğŸ˜­   true: ['ğŸ‘€']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "predicted (0.0573): ğŸ˜‚   true: ['ğŸ˜Š']\n",
      "\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_test.shape[0]):\n",
    "    true_emojis = np.nonzero(y_test[i])\n",
    "    true_emojis_graphics = [emoji_list[k] for k in true_emojis[0].tolist()]\n",
    "    predicted_emoji = emoji_list[np.argmax(y_pred[i])]\n",
    "    predicted_proba = max(y_pred[i])\n",
    "    print(\"predicted ({0:.4f}):\".format(predicted_proba), predicted_emoji, '  true:', true_emojis_graphics )\n",
    "    print('\\n**************************\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On any sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T23:26:37.931289Z",
     "start_time": "2020-12-16T23:26:29.188496Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "embedder = CamembertModel.from_pretrained('camembert-base')\n",
    "classifier = keras.models.load_model(\"/Users/Thomas/Downloads/emoji-predictor/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T00:44:08.621591Z",
     "start_time": "2020-12-17T00:44:03.336214Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"J'adore la musique de Jul\"\n",
    "token_ids = torch.tensor(tokenizer.encode(clean(text))).unsqueeze(0)\n",
    "embedding = embedder(token_ids)[0]\n",
    "cls_embedding = np.matrix(embedding.squeeze()[0].detach().numpy())\n",
    "pred = classifier.predict(cls_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T01:36:47.825990Z",
     "start_time": "2020-12-17T01:36:47.682842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜­\n",
      "ğŸ˜… ğŸ˜­ ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/Thomas/Downloads/emoji-predictor/top100.txt') as f:\n",
    "    emoji_list = ast.literal_eval(f.read())\n",
    "\n",
    "top_emoji = emoji_list[np.argmax(pred)]\n",
    "top3_emojis = [emoji_list[k] for k in np.argpartition(pred[0], -3)[-3:].tolist()]\n",
    "\n",
    "print(top_emoji)\n",
    "print(' '.join(top3_emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T14:55:42.075906Z",
     "start_time": "2020-12-17T14:55:42.019240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ˜­\n",
      "ğŸ‘ ğŸ˜­ ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/Thomas/Downloads/emoji-predictor/top100.txt') as f:\n",
    "    emoji_list = ast.literal_eval(f.read())\n",
    "\n",
    "top_emoji = emoji_list[np.argmax(pred)]\n",
    "top3_emojis = [emoji_list[k] for k in np.argpartition(pred[0], -3)[-3:].tolist()]\n",
    "\n",
    "print(top_emoji)\n",
    "print(' '.join(top3_emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T14:56:47.372776Z",
     "start_time": "2020-12-17T14:56:47.366781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04728341, 0.0711104, 0.061371326]\n"
     ]
    }
   ],
   "source": [
    "top_proba = max(pred[0])\n",
    "top3_proba = [pred[0][k] for k in np.argpartition(pred[0], -3)[-3:].tolist()]\n",
    "print(top3_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T15:41:30.204334Z",
     "start_time": "2020-12-17T15:41:28.408842Z"
    }
   },
   "outputs": [],
   "source": [
    "mod = keras.models.load_model(\"/Users/Thomas/Downloads/final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T15:41:31.365495Z",
     "start_time": "2020-12-17T15:41:31.336509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               6500      \n",
      "=================================================================\n",
      "Total params: 117,028\n",
      "Trainable params: 115,108\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
