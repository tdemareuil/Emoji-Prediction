{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-16T18:01:00.796956Z",
     "iopub.status.busy": "2020-12-16T18:01:00.796080Z",
     "iopub.status.idle": "2020-12-16T18:01:00.817662Z",
     "shell.execute_reply": "2020-12-16T18:01:00.817031Z"
    },
    "papermill": {
     "duration": 0.040966,
     "end_time": "2020-12-16T18:01:00.817795",
     "exception": false,
     "start_time": "2020-12-16T18:01:00.776829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweets/100k_tweets_and_encodings_min_1_emoji_from_top100.csv\n",
      "/kaggle/input/tweets/tweets_fr.txt\n",
      "/kaggle/input/tweets/1M_tweets_and_encodings.csv/1M_tweets_and_encodings.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-16T18:01:00.845822Z",
     "iopub.status.busy": "2020-12-16T18:01:00.845172Z",
     "iopub.status.idle": "2020-12-16T18:01:02.538097Z",
     "shell.execute_reply": "2020-12-16T18:01:02.537383Z"
    },
    "papermill": {
     "duration": 1.708068,
     "end_time": "2020-12-16T18:01:02.538212",
     "exception": false,
     "start_time": "2020-12-16T18:01:00.830144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NROWS = 100000\n",
    "df = pd.read_csv('/kaggle/input/tweets/100k_tweets_and_encodings_min_1_emoji_from_top100.csv', nrows=NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:01:02.577337Z",
     "iopub.status.busy": "2020-12-16T18:01:02.576555Z",
     "iopub.status.idle": "2020-12-16T18:01:02.669661Z",
     "shell.execute_reply": "2020-12-16T18:01:02.670153Z"
    },
    "papermill": {
     "duration": 0.119034,
     "end_time": "2020-12-16T18:01:02.670276",
     "exception": false,
     "start_time": "2020-12-16T18:01:02.551242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>emoji_0</th>\n",
       "      <th>emoji_1</th>\n",
       "      <th>emoji_2</th>\n",
       "      <th>emoji_3</th>\n",
       "      <th>emoji_4</th>\n",
       "      <th>emoji_5</th>\n",
       "      <th>emoji_6</th>\n",
       "      <th>emoji_7</th>\n",
       "      <th>...</th>\n",
       "      <th>emoji_90</th>\n",
       "      <th>emoji_91</th>\n",
       "      <th>emoji_92</th>\n",
       "      <th>emoji_93</th>\n",
       "      <th>emoji_94</th>\n",
       "      <th>emoji_95</th>\n",
       "      <th>emoji_96</th>\n",
       "      <th>emoji_97</th>\n",
       "      <th>emoji_98</th>\n",
       "      <th>emoji_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@chlechevalier @agnesbuzyn @googlenews macron ...</td>\n",
       "      <td>macron n a pas honte de faire la f√™te brizitte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>et vous ? ü•∞ bonne ann√©e les amis ! üíÉ twitterli...</td>\n",
       "      <td>et vous bonne ann√©e les amis twitterlink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>villa br√ªl√©e ‚úÖ bient√¥t la venue de mujdat üôÉ #l...</td>\n",
       "      <td>villa br√ªl√©e bient√¥t la venue de mujdat lmvsmo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mary poppins - supercalifragilisticexpialidoci...</td>\n",
       "      <td>mary poppins supercalifragilisticexpialidociou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>le seul truc qui me choque dans house of cards...</td>\n",
       "      <td>le seul truc qui me choque dans house of cards...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>@lindalovefoxxx ooooh chet ü§§ ü§§ üëÖ üëÖ üëÖ üëÖ üçÜ\\n</td>\n",
       "      <td>ooooh chet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>@fortnitefr et les champions de drogue c ' est...</td>\n",
       "      <td>et les champions de drogue c est autoris√©</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>[ #brestatlantiques ] ü§ó h - 1 avant le grand d...</td>\n",
       "      <td>brestatlantiques h 1 avant le grand d√©part de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>gagner 230e au casino pour bien commencer l ‚Äô ...</td>\n",
       "      <td>gagner 230e au casino pour bien commencer l ann√©e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>demain c ‚Äô est mon anniv , mes parents ne m ‚Äô ...</td>\n",
       "      <td>demain c est mon anniv mes parents ne m ont m√™...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows √ó 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_tweet  \\\n",
       "0      @chlechevalier @agnesbuzyn @googlenews macron ...   \n",
       "1      et vous ? ü•∞ bonne ann√©e les amis ! üíÉ twitterli...   \n",
       "2      villa br√ªl√©e ‚úÖ bient√¥t la venue de mujdat üôÉ #l...   \n",
       "3      mary poppins - supercalifragilisticexpialidoci...   \n",
       "4      le seul truc qui me choque dans house of cards...   \n",
       "...                                                  ...   \n",
       "99995         @lindalovefoxxx ooooh chet ü§§ ü§§ üëÖ üëÖ üëÖ üëÖ üçÜ\\n   \n",
       "99996  @fortnitefr et les champions de drogue c ' est...   \n",
       "99997  [ #brestatlantiques ] ü§ó h - 1 avant le grand d...   \n",
       "99998  gagner 230e au casino pour bien commencer l ‚Äô ...   \n",
       "99999  demain c ‚Äô est mon anniv , mes parents ne m ‚Äô ...   \n",
       "\n",
       "                                             clean_tweet  emoji_0  emoji_1  \\\n",
       "0      macron n a pas honte de faire la f√™te brizitte...        0        0   \n",
       "1               et vous bonne ann√©e les amis twitterlink        0        0   \n",
       "2      villa br√ªl√©e bient√¥t la venue de mujdat lmvsmo...        0        0   \n",
       "3      mary poppins supercalifragilisticexpialidociou...        0        0   \n",
       "4      le seul truc qui me choque dans house of cards...        0        0   \n",
       "...                                                  ...      ...      ...   \n",
       "99995                                         ooooh chet        0        0   \n",
       "99996          et les champions de drogue c est autoris√©        0        0   \n",
       "99997  brestatlantiques h 1 avant le grand d√©part de ...        0        0   \n",
       "99998  gagner 230e au casino pour bien commencer l ann√©e        0        0   \n",
       "99999  demain c est mon anniv mes parents ne m ont m√™...        0        0   \n",
       "\n",
       "       emoji_2  emoji_3  emoji_4  emoji_5  emoji_6  emoji_7  ...  emoji_90  \\\n",
       "0            0        0        0        0        0        0  ...         0   \n",
       "1            0        0        0        0        0        0  ...         0   \n",
       "2            0        0        0        0        0        0  ...         0   \n",
       "3            0        1        0        0        0        0  ...         0   \n",
       "4            0        0        0        0        0        0  ...         0   \n",
       "...        ...      ...      ...      ...      ...      ...  ...       ...   \n",
       "99995        0        0        0        0        0        0  ...         0   \n",
       "99996        0        0        0        0        0        0  ...         0   \n",
       "99997        0        0        0        0        0        0  ...         0   \n",
       "99998        0        0        0        0        0        1  ...         0   \n",
       "99999        0        0        0        0        0        0  ...         0   \n",
       "\n",
       "       emoji_91  emoji_92  emoji_93  emoji_94  emoji_95  emoji_96  emoji_97  \\\n",
       "0             0         0         0         0         0         0         0   \n",
       "1             0         0         0         0         0         0         0   \n",
       "2             0         0         0         0         0         0         0   \n",
       "3             0         0         0         0         0         0         0   \n",
       "4             0         0         0         0         0         0         0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "99995         0         0         0         0         0         0         0   \n",
       "99996         0         0         0         0         0         0         0   \n",
       "99997         0         0         0         0         0         0         0   \n",
       "99998         0         0         0         0         0         0         0   \n",
       "99999         0         0         0         0         0         0         0   \n",
       "\n",
       "       emoji_98  emoji_99  \n",
       "0             0         0  \n",
       "1             0         0  \n",
       "2             0         0  \n",
       "3             0         0  \n",
       "4             0         0  \n",
       "...         ...       ...  \n",
       "99995         0         0  \n",
       "99996         0         0  \n",
       "99997         0         0  \n",
       "99998         0         0  \n",
       "99999         0         0  \n",
       "\n",
       "[100000 rows x 102 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:01:02.698618Z",
     "iopub.status.busy": "2020-12-16T18:01:02.697924Z",
     "iopub.status.idle": "2020-12-16T18:01:29.709070Z",
     "shell.execute_reply": "2020-12-16T18:01:29.708537Z"
    },
    "papermill": {
     "duration": 27.026515,
     "end_time": "2020-12-16T18:01:29.709198",
     "exception": false,
     "start_time": "2020-12-16T18:01:02.682683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf\r\n",
      "  Downloading omegaconf-2.0.5-py3-none-any.whl (36 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf) (3.7.4.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf) (5.3.1)\r\n",
      "Installing collected packages: omegaconf\r\n",
      "Successfully installed omegaconf-2.0.5\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting hydra-core\r\n",
      "  Downloading hydra_core-1.0.4-py3-none-any.whl (122 kB)\r\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 122 kB 861 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: omegaconf>=2.0.5 in /opt/conda/lib/python3.7/site-packages (from hydra-core) (2.0.5)\r\n",
      "Collecting antlr4-python3-runtime==4.8\r\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\r\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112 kB 3.3 MB/s \r\n",
      "\u001b[?25hCollecting importlib-resources\r\n",
      "  Downloading importlib_resources-3.3.0-py2.py3-none-any.whl (26 kB)\r\n",
      "Requirement already satisfied: zipp>=0.4 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2.0.5->hydra-core) (3.7.4.1)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.7/site-packages (from omegaconf>=2.0.5->hydra-core) (5.3.1)\r\n",
      "Building wheels for collected packages: antlr4-python3-runtime\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=ec8d44a3474749f0d3a95274eaf6642c472c73a54b601bbf8d453da52cc591d6\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\r\n",
      "Successfully built antlr4-python3-runtime\r\n",
      "Installing collected packages: importlib-resources, antlr4-python3-runtime, hydra-core\r\n",
      "Successfully installed antlr4-python3-runtime-4.8 hydra-core-1.0.4 importlib-resources-3.3.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.7.0)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch) (0.18.2)\r\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.1)\r\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch) (0.6)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch) (1.18.5)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install omegaconf\n",
    "!pip install hydra-core\n",
    "!pip install torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:01:29.758804Z",
     "iopub.status.busy": "2020-12-16T18:01:29.757984Z",
     "iopub.status.idle": "2020-12-16T18:04:22.043438Z",
     "shell.execute_reply": "2020-12-16T18:04:22.044019Z"
    },
    "papermill": {
     "duration": 172.313321,
     "end_time": "2020-12-16T18:04:22.044179",
     "exception": false,
     "start_time": "2020-12-16T18:01:29.730858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n",
      "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
      "building 'fairseq.libbleu' extension\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu\n",
      "Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/fairseq\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.data.data_utils_fast' extension\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data\n",
      "Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.data.token_block_utils_fast' extension\n",
      "Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.libnat' extension\n",
      "creating /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libnat\n",
      "Emitting ninja build file /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ /root/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so -> fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so -> fairseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1012630426/1012630426 [01:31<00:00, 11015397.24B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerSentenceEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(32005, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "camembert = torch.hub.load('pytorch/fairseq', 'camembert')\n",
    "camembert.eval()  # disable dropout (or leave in train mode to finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:22.640459Z",
     "iopub.status.busy": "2020-12-16T18:04:22.639590Z",
     "iopub.status.idle": "2020-12-16T18:04:23.005437Z",
     "shell.execute_reply": "2020-12-16T18:04:23.006082Z"
    },
    "papermill": {
     "duration": 0.672704,
     "end_time": "2020-12-16T18:04:23.006236",
     "exception": false,
     "start_time": "2020-12-16T18:04:22.333532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/torch/hub/pytorch_fairseq_master/fairseq/models/roberta/hub_interface.py:176: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729141890/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  masked_index = (tokens == self.task.mask_idx).nonzero()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(\"J'aime me beurrer la joue \", 0.11025537550449371, ' joue'),\n",
       " (\"J'aime me beurrer la bouche \", 0.0751555860042572, ' bouche'),\n",
       " (\"J'aime me beurrer la peau \", 0.05565204098820686, ' peau'),\n",
       " (\"J'aime me beurrer la main \", 0.04818896949291229, ' main'),\n",
       " (\"J'aime me beurrer la moustache \", 0.0477130189538002, ' moustache'),\n",
       " (\"J'aime me beurrer la nuque \", 0.03552733734250069, ' nuque'),\n",
       " (\"J'aime me beurrer la cuisse \", 0.022842274978756905, ' cuisse'),\n",
       " (\"J'aime me beurrer la tronche \", 0.022781599313020706, ' tronche'),\n",
       " (\"J'aime me beurrer la moule \", 0.02265654131770134, ' moule'),\n",
       " (\"J'aime me beurrer la cervelle \", 0.022106261923909187, ' cervelle')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_line = \"J'aime me beurrer la <mask> \"\n",
    "camembert.fill_mask(masked_line, topk=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:23.823928Z",
     "iopub.status.busy": "2020-12-16T18:04:23.822666Z",
     "iopub.status.idle": "2020-12-16T18:04:23.941137Z",
     "shell.execute_reply": "2020-12-16T18:04:23.940342Z"
    },
    "papermill": {
     "duration": 0.516185,
     "end_time": "2020-12-16T18:04:23.941290",
     "exception": false,
     "start_time": "2020-12-16T18:04:23.425105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"J'aime le camembert !\"\n",
    "tokens = camembert.encode(line)\n",
    "last_layer_features = camembert.extract_features(tokens, return_all_hiddens=False)\n",
    "last_layer_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:24.544885Z",
     "iopub.status.busy": "2020-12-16T18:04:24.544201Z",
     "iopub.status.idle": "2020-12-16T18:04:24.595570Z",
     "shell.execute_reply": "2020-12-16T18:04:24.594841Z"
    },
    "papermill": {
     "duration": 0.358352,
     "end_time": "2020-12-16T18:04:24.595710",
     "exception": false,
     "start_time": "2020-12-16T18:04:24.237358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_tweets = df['clean_tweet'].values\n",
    "clean_tweets=clean_tweets.astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:25.482430Z",
     "iopub.status.busy": "2020-12-16T18:04:25.480240Z",
     "iopub.status.idle": "2020-12-16T18:04:25.488393Z",
     "shell.execute_reply": "2020-12-16T18:04:25.488898Z"
    },
    "papermill": {
     "duration": 0.4523,
     "end_time": "2020-12-16T18:04:25.489023",
     "exception": false,
     "start_time": "2020-12-16T18:04:25.036723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_features.size()\n",
    "token_embeddings = torch.squeeze(last_layer_features, dim=0)\n",
    "token_embeddings.size()\n",
    "sentence_embedding = torch.mean(token_embeddings, dim=0)\n",
    "sentence_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:26.087403Z",
     "iopub.status.busy": "2020-12-16T18:04:26.086766Z",
     "iopub.status.idle": "2020-12-16T18:04:26.092865Z",
     "shell.execute_reply": "2020-12-16T18:04:26.092060Z"
    },
    "papermill": {
     "duration": 0.306787,
     "end_time": "2020-12-16T18:04:26.093002",
     "exception": false,
     "start_time": "2020-12-16T18:04:25.786215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-16T18:04:27.053141Z",
     "iopub.status.busy": "2020-12-16T18:04:26.997567Z",
     "iopub.status.idle": "2020-12-17T00:09:33.251054Z",
     "shell.execute_reply": "2020-12-17T00:09:33.251704Z"
    },
    "papermill": {
     "duration": 21906.718002,
     "end_time": "2020-12-17T00:09:33.251889",
     "exception": false,
     "start_time": "2020-12-16T18:04:26.533887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871ecd5de2d14e47909384cf22a19de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clean_tweets = df['clean_tweet'].values.astype('str')\n",
    "#print(type(clean_tweets[0]))\n",
    "empty = []\n",
    "sentence_embeddings = np.array(empty)\n",
    "len(clean_tweets)\n",
    "for tweet in tqdm(clean_tweets) :\n",
    "    tokens = camembert.encode(tweet)\n",
    "    last_layer_features = camembert.extract_features(tokens) # On prend la derni√®re couche de BERT pour chacun des tokens \n",
    "    token_embeddings = torch.squeeze(last_layer_features, dim=0) # On enl√®ve la dimension inutile qui vaut 1 car on n'a qu'une phrase\n",
    "    sentence_embedding = torch.mean(token_embeddings, dim=0).detach().numpy() # On fait la moyenne sur tous les tokens pour \"projeter\" i.e passer de [n_tokens,768] √† [768] \n",
    "    sentence_embeddings = np.append(sentence_embeddings, sentence_embedding)\n",
    "#stacked_encodings = np.stack(sentence_embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T00:09:33.860463Z",
     "iopub.status.busy": "2020-12-17T00:09:33.859635Z",
     "iopub.status.idle": "2020-12-17T00:09:33.864967Z",
     "shell.execute_reply": "2020-12-17T00:09:33.864368Z"
    },
    "papermill": {
     "duration": 0.30668,
     "end_time": "2020-12-17T00:09:33.865064",
     "exception": false,
     "start_time": "2020-12-17T00:09:33.558384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings = sentence_embeddings.reshape(NROWS,768)\n",
    "sentence_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T00:09:34.464836Z",
     "iopub.status.busy": "2020-12-17T00:09:34.463394Z",
     "iopub.status.idle": "2020-12-17T00:10:57.736560Z",
     "shell.execute_reply": "2020-12-17T00:10:57.737283Z"
    },
    "papermill": {
     "duration": 83.573059,
     "end_time": "2020-12-17T00:10:57.737522",
     "exception": false,
     "start_time": "2020-12-17T00:09:34.164463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt('100k_sentence_embeddings_min_1_emoji_from_top100.csv', sentence_embeddings, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.47937,
     "end_time": "2020-12-17T00:10:58.680391",
     "exception": false,
     "start_time": "2020-12-17T00:10:58.201021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.455858,
     "end_time": "2020-12-17T00:11:00.858435",
     "exception": false,
     "start_time": "2020-12-17T00:11:00.402577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 22205.764816,
   "end_time": "2020-12-17T00:11:01.428934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-16T18:00:55.664118",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e9725b987de456fb3e8e5157d20aaf2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c22b97713ec4da989656773a550145c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "49dd57a825124923b897315fa49f155f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b4380ded3f74ff7a5de45cea53b25c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "871ecd5de2d14e47909384cf22a19de9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0a7ee44ecdb468e871823f4e74ae127",
        "IPY_MODEL_a01facf75e84465d87faac8e13b17232"
       ],
       "layout": "IPY_MODEL_0e9725b987de456fb3e8e5157d20aaf2"
      }
     },
     "a01facf75e84465d87faac8e13b17232": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aa1e41e071b544eab73f2183f3763661",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7b4380ded3f74ff7a5de45cea53b25c5",
       "value": " 100000/100000 [6:05:06&lt;00:00,  4.56it/s]"
      }
     },
     "aa1e41e071b544eab73f2183f3763661": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0a7ee44ecdb468e871823f4e74ae127": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49dd57a825124923b897315fa49f155f",
       "max": 100000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2c22b97713ec4da989656773a550145c",
       "value": 100000.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
